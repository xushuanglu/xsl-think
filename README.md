														自己的思考步骤总结
														2019年03月06日   version 1.0


1、如何系统的去学习掌握一门技术？
例如：自旋锁
(1)实现原理是什么？
	所谓自旋锁，就是让该线程等待一段时间，不会被立即挂起，看持有锁的线程是否会很快释放锁。
(2)使用的场景是什么？
	线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。所以引入自旋锁。
(3)包括哪些基础内容？
	自旋等待不能替代阻塞，先不说对处理器数量的要求（多核，貌似现在没有单核的处理器了），虽然它可以避免线程切换带来的开销，但是它占用了处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，它不会做任何有意义的工作，典型的占着茅坑不拉屎，这样反而会带来性能上的浪费。所以说，自旋等待的时间（自旋的次数）必须要有一个限度，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起。 
(4)如何使用？
(5)注意事项是什么？
	自旋锁在JDK 1.4.2中引入，默认关闭，但是可以使用-XX:+UseSpinning开开启，在JDK1.6中默认开启。同时自旋的默认次数为10次，可以通过参数-XX:PreBlockSpin来调整。
	如果通过参数-XX:preBlockSpin来调整自旋锁的自旋次数，会带来诸多不便。假如我将参数调整为10，但是系统很多线程都是等你刚刚退出的时候就释放了锁（假如你多自旋一两次就可以获取锁），你是不是很尴尬。于是JDK1.6引入自适应的自旋锁，让虚拟机会变得越来越聪明。
(6)优缺点？
(7)如何进行优化操作？
(8)同款技术的区别是什么？


例如：适应自旋锁
(1)实现原理是什么？
	所谓自适应就意味着自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。
(2)使用的场景是什么？
(3)包括哪些基础内容？
(4)如何使用？
	线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。 
(5)注意事项是什么？
(6)优缺点？
	有了自适应自旋锁，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测会越来越准确，虚拟机会变得越来越聪明。
(7)如何进行优化操作？
(8)同款技术的区别是什么？

例如：锁消除
(2)使用的场景是什么？
	为了保证数据的完整性，我们在进行操作时需要对这部分操作进行同步控制，但是在有些情况下，JVM检测到不可能存在共享数据竞争，这是JVM会对这些同步锁进行锁消除。锁消除的依据是逃逸分析的数据支持。
(1)实现原理是什么？
(3)包括哪些基础内容？
	变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是对于我们程序员来说这还不清楚么？我们会在明明知道不存在数据竞争的代码块前加上同步吗？但是有时候程序并不是我们所想的那样？我们虽然没有显示使用锁，但是我们在使用一些JDK的内置API时，如StringBuffer、Vector、HashTable等，这个时候会存在隐形的加锁操作。比如StringBuffer的append()方法，Vector的add()方法：
(4)如何使用？
(5)注意事项是什么？
(6)优缺点？
	所以锁消除可以节省毫无意义的请求锁的时间。
(7)如何进行优化操作？
(8)同款技术的区别是什么？


例如：锁粗化
(2)使用的场景是什么？
	我们知道在使用同步锁的时候，需要让同步块的作用范围尽可能小―仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。但是如果一系列的连续加锁解锁操作，可能会导致不必要的性能损耗，所以引入锁粗话的概念。
(1)实现原理是什么？
	锁粗话概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。
(3)包括哪些基础内容？
(9)举例？
	public void vectorTest(){
        Vector<String> vector = new Vector<String>();
        for(int i = 0 ; i < 10 ; i++){
            vector.add(i + "");
        }
        System.out.println(vector);
    }
	如上面实例：vector每次add的时候都需要加锁操作，JVM检测到对同一个对象（vector）连续加锁、解锁操作，会合并一个更大范围的加锁、解锁操作，即加锁解锁操作会移到for循环之外。
	
(4)如何使用？
(5)注意事项是什么？
(6)优缺点？
(7)如何进行优化操作？
(8)同款技术的区别是什么？


例如：轻量级锁
(2)使用的场景是什么？
	引入轻量级锁的主要目的是在多没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁
(1)实现原理是什么？
(3)包括哪些基础内容？
	获取锁：
		1、判断当前对象是否处于无锁状态（hashcode、0、01），若是，则JVM首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word）；否则执行步骤（3）；
		2、JVM利用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指正，如果成功表示竞争到锁，则将锁标志位变成00（表示此对象处于轻量级锁状态），执行同步操作；如果失败则执行步骤（3）；
		3、判断当前对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态；
	释放锁：(轻量级锁的释放也是通过CAS操作来进行的，主要步骤如下：)
		1、取出在获取轻量级锁保存在Displaced Mark Word中的数据；
		2、用CAS操作将取出的数据替换当前对象的Mark Word中，如果成功，则说明释放锁成功，否则执行（3）；
		3、如果CAS操作替换失败，说明有其他线程尝试获取该锁，则需要在释放锁的同时需要唤醒被挂起的线程。
(9)举例？
(4)如何使用？
(5)注意事项是什么？
	对于轻量级锁，其性能提升的依据是“对于绝大部分的锁，在整个生命周期内都是不会存在竞争的”，如果打破这个依据则除了互斥的开销外，还有额外的CAS操作，因此在有多线程竞争的情况下，轻量级锁比重量级锁更慢；
(6)优缺点？
(7)如何进行优化操作？
(8)同款技术的区别是什么？


例如：偏向锁
(2)使用的场景是什么？
	引入偏向锁主要目的是：为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径。上面提到了轻量级锁的加锁解锁操作是需要依赖多次CAS原子指令的。
(1)实现原理是什么？
	我们可以查看Mark work的结构就明白了。只需要检查是否为偏向锁、锁标识为以及ThreadID即可，处理流程如下：
	获取锁：
		1、检测Mark Word是否为可偏向状态，即是否为偏向锁1，锁标识位为01；
		2、若为可偏向状态，则测试线程ID是否为当前线程ID，如果是，则执行步骤（5），否则执行步骤（3）；
		3、如果线程ID不为当前线程ID，则通过CAS操作竞争锁，竞争成功，则将Mark Word的线程ID替换为当前线程ID，否则执行线程（4）；
		4、通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码块；
		5、执行同步代码块
	释放锁 ：
		偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。其步骤如下：
		1、暂停拥有偏向锁的线程，判断锁对象石是否还处于被锁定状态；
		2、撤销偏向苏，恢复到无锁状态（01）或者轻量级锁的状态；
		
(3)包括哪些基础内容？
(9)举例？
(4)如何使用？
(5)注意事项是什么？
(6)优缺点？
(7)如何进行优化操作？
(8)同款技术的区别是什么？


例如：重量级锁
(2)使用的场景是什么？
(1)实现原理是什么？
	重量级锁通过对象内部的监视器（monitor）实现，其中monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。
(3)包括哪些基础内容？
(9)举例？
(4)如何使用？
(5)注意事项是什么？
(6)优缺点？
(7)如何进行优化操作？
(8)同款技术的区别是什么？



【死磕Java并发】-----深入分析volatile的实现原理

例如：volatile
(2)使用的场景是什么？
	通过前面一章我们了解了synchronized是一个重量级的锁，虽然JVM对它做了很多优化，而下面介绍的volatile则是轻量级的synchronized。如果一个变量使用volatile，则它比使用synchronized的成本更加低，因为它不会引起线程上下文的切换和调度
	
	当线程运行这段代码时，首先会从主存中读取i( i = 1)，然后复制一份到CPU高速缓存中，然后CPU执行 + 1 （2）的操作，然后将数据（2）写入到告诉缓存中，最后刷新到主存中。其实这样做在单线程中是没有问题的，有问题的是在多线程中。如下：
假如有两个线程A、B都执行这个操作（i++），按照我们正常的逻辑思维主存中的i值应该=3，但事实是这样么？分析如下：
	两个线程从主存中读取i的值（1）到各自的高速缓存中，然后线程A执行+1操作并将结果写入高速缓存中，最后写入主存中，此时主存i==2,线程B做同样的操作，主存中的i仍然=2。所以最终结果为2并不是3。这种现象就是缓存一致性问题。
	
(1)实现原理是什么？
	Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。
	剖析volatile原理
		volatile可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在JVM底层volatile是采用“内存屏障”来实现的。
			1、保证可见性、不保证原子性
			2、禁止指令重排序
				在执行程序时为了提高性能，编译器和处理器通常会对指令做重排序：
					1、编译器重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序；
					2、处理器重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序；
(3)包括哪些基础内容？
	内存模型相关概念：理解volatile其实还是有点儿难度的，它与Java的内存模型有关
	操作系统语义：计算机在运行程序时，每条指令都是在CPU中执行的，在执行过程中势必会涉及到数据的读写。我们知道程序运行的数据是存储在主存中，这时就会有一个问题，读写主存中的数据没有CPU中执行指令的速度快，如果任何的交互都需要与主存打交道则会大大影响效率，所以就有了CPU高速缓存。CPU高速缓存为某个CPU独有，只与在该CPU运行的线程有关。
	Java内存模型:在并发编程中我们一般都会遇到这三个基本概念：
		原子性、
			原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。
				在单线程环境下我们可以认为整个步骤都是原子性操作，但是在多线程环境下则不同，Java只保证了基本数据类型的变量和赋值操作才是原子性的（注：在32位的JDK环境下，对64位数据的读取不是原子性操作*，如long、double）。要想在多线程环境下保证原子性，则可以通过锁、synchronized来确保。
			volatile是无法保证复合操作的原子性
		可见性、
			可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。
			Java提供了volatile来保证可见性。
			当一个变量被volatile修饰后，表示着线程本地内存无效，当一个线程修改共享变量后他会立即被更新到主内存中，当其他线程读取共享变量时，它会直接从主内存中读取。 
当然，synchronize和锁都可以保证可见性。
		有序性。
			有序性：即程序执行的顺序按照代码的先后顺序执行。
			在Java内存模型中，为了效率是允许编译器和处理器对指令进行重排序，当然重排序它不会影响单线程的运行结果，但是对多线程会有影响。
Java提供volatile来保证一定的有序性。最著名的例子就是单例模式里面的DCL（双重检查锁）。
	
	
(9)举例？
	解决缓存一致性方案有两种：
		1、通过在总线加LOCK#锁的方式
			但是方案1存在一个问题，它是采用一种独占的方式来实现的，即总线加LOCK#锁的话，只能有一个CPU能够运行，其他CPU都得阻塞，效率较为低下。
		2、通过缓存一致性协议
			第二种方案，缓存一致性协议（MESI协议）它确保每个缓存中使用的共享变量的副本是一致的。其核心思想如下：当某个CPU在写数据时，如果发现操作的变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，因此其他CPU在读取该变量时，发现其无效会重新从主存中加载数据。 
		
(4)如何使用？
(5)注意事项是什么？
(6)优缺点？
(7)如何进行优化操作？
(8)同款技术的区别是什么？
(9)总结
	volatile看起来简单，但是要想理解它还是比较难的，这里只是对其进行基本的了解。volatile相对于synchronized稍微轻量些，在某些场合它可以替代synchronized，但是又不能完全取代synchronized，只有在某些场合才能够使用volatile。使用它必须满足如下两个条件：
	1、对变量的写操作不依赖当前值；
	2、该变量没有包含在具有其他变量的不变式中。
    volatile经常用于两个两个场景：状态标记两、double check 

    
    
【死磕Java并发】―CJava内存模型之happens-before
  
1、在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。
	happens-before原则非常重要，它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们解决在并发环境下两操作之间是否可能存在冲突的所有问题。
happens-before原则定义如下：

1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 
2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。

下面是happens-before原则规则：

	1、程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
	2、锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作；
	3、volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
	4、传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
	5、线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；
	6、线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
	7、线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
	8、对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；
	我们来详细看看上面每条规则（摘自《深入理解Java虚拟机第12章》）：
	
	程序次序规则：一段代码在单线程中执行的结果是有序的。注意是执行结果，因为虚拟机、处理器会对指令进行重排序（重排序后面会详细介绍）。虽然重排序了，但是并不会影响程序的执行结果，所以程序最终执行的结果与顺序执行的结果是一致的。故而这个规则只对单线程有效，在多线程环境下无法保证正确性。
	
	锁定规则：这个规则比较好理解，无论是在单线程环境还是多线程环境，一个锁处于被锁定状态，那么必须先执行unlock操作后面才能进行lock操作。

	volatile变量规则：这是一条比较重要的规则，它标志着volatile保证了线程可见性。通俗点讲就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作一定是happens-before读操作的。

	传递规则：提现了happens-before原则具有传递性，即A happens-before B , B happens-before C，那么A happens-before C

	线程启动规则：假定线程A在执行过程中，通过执行ThreadB.start()来启动线程B，那么线程A对共享变量的修改在接下来线程B开始执行后确保对线程B可见。

	线程终结规则：假定线程A在执行的过程中，通过制定ThreadB.join()等待线程B终止，那么线程B在终止之前对共享变量的修改在线程A等待返回后可见。

上面八条是原生Java满足Happens-before关系的规则，但是我们可以对他们进行推导出其他满足happens-before的规则：

	将一个元素放入一个线程安全的队列的操作Happens-Before从队列中取出这个元素的操作
	将一个元素放入一个线程安全容器的操作Happens-Before从容器中取出这个元素的操作
	在CountDownLatch上的倒数操作Happens-Before CountDownLatch#await()操作
	释放Semaphore许可的操作Happens-Before获得许可操作
	Future表示的任务的所有操作Happens-Before Future#get()操作
	向Executor提交一个Runnable或Callable的操作Happens-Before任务开始执行操作
	这里再说一遍happens-before的概念：如果两个操作不存在上述（前面8条 + 后面6条）任一一个happens-before规则，那么这两个操作就没有顺序的保障，JVM可以对这两个操作进行重排序。如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的。
	
	下面就用一个简单的例子来描述下happens-before原则：
	
	private int i = 0;public void write(int j ){
		i = j;}public int read(){
		return i;}
	我们约定线程A执行write()，线程B执行read()，且线程A优先于线程B执行，那么线程B获得结果是什么？；我们就这段简单的代码一次分析happens-before的规则（规则5、6、7、8 + 推导的6条可以忽略，因为他们和这段代码毫无关系）：
	
	1、由于两个方法是由不同的线程调用，所以肯定不满足程序次序规则；
	2、两个方法都没有使用锁，所以不满足锁定规则；
	3、变量i不是用volatile修饰的，所以volatile变量规则不满足；
	4、传递规则肯定不满足；
	所以我们无法通过happens-before原则推导出线程A happens-before线程B，虽然可以确认在时间上线程A优先于线程B指定，但是就是无法确认线程B获得的结果是什么，所以这段代码不是线程安全的。那么怎么修复这段代码呢？满足规则2、3任一即可。
	
	happen-before原则是JMM中非常重要的原则，它是判断数据是否存在竞争、线程是否安全的主要依据，保证了多线程环境下的可见性。